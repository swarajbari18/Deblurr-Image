import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision.transforms.functional import rotate
import numpy as np
import math
import warnings

from itertools import repeat
import collections.abc




def window_partition(x, window_size):
    """
    Args:
        x: (B, H, W, C)
        window_size (int): window size

    Returns:
        windows: (num_windows*B, window_size, window_size, C)
    """
    B, H, W, C = x.shape
    x = x.view(B, H // window_size, window_size, W // window_size, window_size, C)
    windows = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(-1, window_size, window_size, C)
    return windows


def window_reverse(windows, window_size, H, W):
    """
    Args:
        windows: (num_windows*B, window_size, window_size, C)
        window_size (int): Window size
        H (int): Height of image
        W (int): Width of image

    Returns:
        x: (B, H, W, C)
    """
    B = int(windows.shape[0] / (H * W / window_size / window_size))
    x = windows.view(B, H // window_size, W // window_size, window_size, window_size, -1)
    x = x.permute(0, 1, 3, 2, 4, 5).contiguous().view(B, H, W, -1)
    return x


def mse():
    return nn.MSELoss()





class DropPath(nn.Module):
    """Drop paths (Stochastic Depth) per sample  (when applied in main path of residual blocks).
    """
    def __init__(self, drop_prob: float = 0., scale_by_keep: bool = True):
        super(DropPath, self).__init__()
        self.drop_prob = drop_prob
        self.scale_by_keep = scale_by_keep

    def forward(self, x):
        return self._drop_path(x, self.drop_prob, self.training, self.scale_by_keep)

    def extra_repr(self):
        return f'drop_prob={round(self.drop_prob,3):0.3f}'
    

    def _drop_path(self, x, drop_prob: float = 0., training: bool = False, scale_by_keep: bool = True):
        """Drop paths (Stochastic Depth) per sample (when applied in main path of residual blocks).
        """
        if drop_prob == 0. or not training:
            return x
        keep_prob = 1 - drop_prob
        shape = (x.shape[0],) + (1,) * (x.ndim - 1)  # work with diff dim tensors, not just 2D ConvNets
        random_tensor = x.new_empty(shape).bernoulli_(keep_prob)
        if keep_prob > 0.0 and scale_by_keep:
            random_tensor.div_(keep_prob)
        return x * random_tensor
    




def _ntuple(n):
    def parse(x):
        if isinstance(x, collections.abc.Iterable) and not isinstance(x, str):
            return tuple(x)
        return tuple(repeat(x, n))
    return parse


to_2tuple = _ntuple(2)


def _trunc_normal_(tensor, mean, std, a, b):
    # Cut & paste from PyTorch official master until it's in a few official releases - RW
    # Method based on https://people.sc.fsu.edu/~jburkardt/presentations/truncated_normal.pdf
    def norm_cdf(x):
        # Computes standard normal cumulative distribution function
        return (1. + math.erf(x / math.sqrt(2.))) / 2.

    if (mean < a - 2 * std) or (mean > b + 2 * std):
        warnings.warn("mean is more than 2 std from [a, b] in nn.init.trunc_normal_. "
                      "The distribution of values may be incorrect.",
                      stacklevel=2)

    # Values are generated by using a truncated uniform distribution and
    # then using the inverse CDF for the normal distribution.
    # Get upper and lower cdf values
    l = norm_cdf((a - mean) / std)
    u = norm_cdf((b - mean) / std)

    # Uniformly fill tensor with values from [l, u], then translate to
    # [2l-1, 2u-1].
    tensor.uniform_(2 * l - 1, 2 * u - 1)

    # Use inverse cdf transform for normal distribution to get truncated
    # standard normal
    tensor.erfinv_()

    # Transform to proper mean, std
    tensor.mul_(std * math.sqrt(2.))
    tensor.add_(mean)

    # Clamp to ensure it's in the proper range
    tensor.clamp_(min=a, max=b)
    return tensor


def trunc_normal_(tensor, mean=0., std=1., a=-2., b=2.):
    # type: (torch.Tensor, float, float, float, float) -> torch.Tensor
    r"""Fills the input Tensor with values drawn from a truncated
    normal distribution. The values are effectively drawn from the
    normal distribution :math:`\mathcal{N}(\text{mean}, \text{std}^2)`
    with values outside :math:`[a, b]` redrawn until they are within
    the bounds. The method used for generating the random values works
    best when :math:`a \leq \text{mean} \leq b`.

    NOTE: this impl is similar to the PyTorch trunc_normal_, the bounds [a, b] are
    applied while sampling the normal with mean/std applied, therefore a, b args
    should be adjusted to match the range of mean, std args.

    Args:
        tensor: an n-dimensional `torch.Tensor`
        mean: the mean of the normal distribution
        std: the standard deviation of the normal distribution
        a: the minimum cutoff value
        b: the maximum cutoff value
    Examples:
        >>> w = torch.empty(3, 5)
        >>> nn.init.trunc_normal_(w)
    """
    with torch.no_grad():
        return _trunc_normal_(tensor, mean, std, a, b)
    



class SupLoss(nn.Module):
    r"""
    Standard supervised loss

    The supervised loss is defined as

    .. math::

        \|x-\inverse{y}\|^2

    where :math:`\inverse{y}` is the reconstructed signal and :math:`x` is the ground truth target.

    By default, the error is computed using the MSE metric, however any other metric (e.g., :math:`\ell_1`)
    can be used as well.

    :param torch.nn.Module metric: metric used for computing data consistency,
        which is set as the mean squared error by default.
    """

    def __init__(self, metric=torch.nn.MSELoss()):
        super(SupLoss, self).__init__()
        self.name = "supervised"
        self.metric = metric

    def forward(self, x, x_net, **kwargs):
        r"""
        Computes the loss.

        :param torch.Tensor x: Target (ground-truth) image.
        :param torch.Tensor x_net: Reconstructed image :math:\inverse{y}.
        :return: (torch.Tensor) loss.
        """
        return self.metric(x_net, x)
    





class SureGaussianLoss(nn.Module):
    r"""
    SURE loss for Gaussian noise

    The loss is designed for the following noise model:

    .. math::

        y \sim\mathcal{N}(u,\sigma^2 I) \quad \text{with}\quad u= A(x).

    The loss is computed as

    .. math::

        \frac{1}{m}\|y - A\inverse{y}\|_2^2 -\sigma^2 +\frac{2\sigma^2}{m\tau}b^{\top} \left(A\inverse{y+\tau b_i} -
        A\inverse{y}\right)

    where :math:`R` is the trainable network, :math:`A` is the forward operator,
    :math:`y` is the noisy measurement vector of size :math:`m`, :math:`A` is the forward operator,
    :math:`b\sim\mathcal{N}(0,I)` and :math:`\tau\geq 0` is a hyperparameter controlling the
    Monte Carlo approximation of the divergence.

    This loss approximates the divergence of :math:`A\inverse{y}` (in the original SURE loss)
    using the Monte Carlo approximation in
    https://ieeexplore.ieee.org/abstract/document/4099398/

    If the measurement data is truly Gaussian with standard deviation :math:`\sigma`,
    this loss is an unbiased estimator of the mean squared loss :math:`\frac{1}{m}\|u-A\inverse{y}\|_2^2`
    where :math:`z` is the noiseless measurement.

    .. warning::

        The loss can be sensitive to the choice of :math:`\tau`, which should be proportional to the size of :math:`y`.
        The default value of 0.01 is adapted to :math:`y` vectors with entries in :math:`[0,1]`.

    :param float sigma: Standard deviation of the Gaussian noise.
    :param float tau: Approximation constant for the Monte Carlo approximation of the divergence.
    """

    def __init__(self, sigma, tau=1e-2):
        super(SureGaussianLoss, self).__init__()
        self.name = "SureGaussian"
        self.sigma2 = sigma**2
        self.tau = tau

    def _mc_div(y1, y, f, physics, tau):
        r"""
        Monte-Carlo estimation for the divergence of A(f(x)).

        :param torch.Tensor y: Measurements.
        :param deepinv.physics.Physics physics: Forward operator associated with the measurements.
        :param torch.nn.Module f: Reconstruction network.
        :param int mc_iter: number of iterations. Default=1.
        :return: (float) hutch divergence.
        """
        b = torch.randn_like(y)
        y2 = physics.A(f(y + b * tau, physics))
        out = (b * (y2 - y1) / tau).mean()
        return out

    def forward(self, y, x_net, physics, model, **kwargs):
        r"""
        Computes the SURE Loss.

        :param torch.Tensor y: Measurements.
        :param torch.Tensor x_net: reconstructed image :math:`\inverse{y}`.
        :param deepinv.physics.Physics physics: Forward operator associated with the measurements.
        :param torch.nn.Module model: Reconstruction network.
        :return: (float) SURE loss.
        """

        y1 = physics.A(x_net)
        div = 2 * self.sigma2 * self._mc_div(y1, y, model, physics, self.tau)
        mse = (y1 - y).pow(2).mean()
        loss_sure = mse + div - self.sigma2
        return loss_sure
    







class EILoss(nn.Module):
    r"""
    Equivariant imaging self-supervised loss.

    Assumes that the set of signals is invariant to a group of transformations (rotations, translations, etc.)
    in order to learn from incomplete measurement data alone https://https://arxiv.org/pdf/2103.14756.pdf.

    The EI loss is defined as

    .. math::

        \| T_g \hat{x} - \inverse{\forw{T_g \hat{x}}}\|^2


    where :math:`\hat{x}=\inverse{y}` is a reconstructed signal and
    :math:`T_g` is a transformation sampled at random from a group :math:`g\sim\group`.

    By default, the error is computed using the MSE metric, however any other metric (e.g., :math:`\ell_1`)
    can be used as well.

    :param deepinv.Transform, torchvision.transforms transform: Transform to generate the virtually
        augmented measurement. It can be any torch-differentiable function (e.g., a ``torch.nn.Module``).
    :param torch.nn.Module metric: Metric used to compute the error between the reconstructed augmented measurement and the reference
        image.
    :param bool apply_noise: if ``True``, the augmented measurement is computed with the full sensing model
        :math:`\sensor{\noise{\forw{\hat{x}}}}` (i.e., noise and sensor model),
        otherwise is generated as :math:`\forw{\hat{x}}`.
    :param float weight: Weight of the loss.
    :param bool no_grad: if ``True``, the gradient does not propagate through :math:`T_g`. Default: ``True``.
    """

    def __init__(
        self,
        transform,
        metric=torch.nn.MSELoss(),
        apply_noise=True,
        weight=1.0,
        no_grad=True,
    ):
        super(EILoss, self).__init__()
        self.name = "ei"
        self.metric = metric
        self.weight = weight
        self.T = transform
        self.noise = apply_noise
        self.no_grad = no_grad

    def forward(self, x_net, physics, model, **kwargs):
        r"""
        Computes the EI loss

        :param torch.Tensor x_net: Reconstructed image :math:`\inverse{y}`.
        :param deepinv.physics.Physics physics: Forward operator associated with the measurements.
        :param torch.nn.Module model: Reconstruction function.
        :return: (torch.Tensor) loss.
        """

        if self.no_grad:
            with torch.no_grad():
                x2 = self.T(x_net)
        else:
            x2 = self.T(x_net)

        if self.noise:
            y = physics(x2)
        else:
            y = physics.A(x2)

        x3 = model(y, physics)

        loss_ei = self.weight * self.metric(x3, x2)
        return loss_ei






class Rotate(torch.nn.Module):
    r"""
    2D Rotations.

    Generates n_transf randomly rotated versions of 2D images with zero padding.

    :param n_trans: number of rotated versions generated per input image.
    :param degrees: images are rotated in the range of angles (-degrees, degrees)
    """

    def __init__(self, n_trans=1, degrees=360):
        super(Rotate, self).__init__()
        self.n_trans, self.group_size = n_trans, degrees

    def forward(self, data):
        if self.group_size == 360:
            theta = np.arange(0, 360)[1:][torch.randperm(359)]
            theta = theta[: self.n_trans]
        else:
            theta = np.arange(0, 360, int(360 / (self.group_size + 1)))[1:]
            theta = theta[torch.randperm(self.group_size)][: self.n_trans]
        return torch.cat([rotate(data, float(_theta)) for _theta in theta])





class Shift(torch.nn.Module):
    r"""
    Fast integer 2D translations.

    Generates n_transf randomly shifted versions of 2D images with circular padding.

    :param n_trans: number of shifted versions generated per input image.
    """

    def __init__(self, n_trans=1):
        super(Shift, self).__init__()
        self.n_trans = n_trans

    def forward(self, data):
        H, W = data.shape[-2:]
        assert self.n_trans <= H - 1 and self.n_trans <= W - 1
        x = torch.arange(-H, H)[torch.randperm(2 * H)][: self.n_trans]
        y = torch.arange(-W, W)[torch.randperm(2 * W)][: self.n_trans]

        out = torch.cat(
            [torch.roll(data, [sx, sy], [-2, -1]) for sx, sy in zip(x, y)], dim=0
        )
        return out


class TensorList:
    r"""

    Represents a list of :class:`torch.Tensor` with different shapes.
    It allows to sum, flatten, append, etc. lists of tensors seamlessly, in a
    similar fashion to :class:`torch.Tensor`.

    :param x: a list of :class:`torch.Tensor`, a single :class:`torch.Tensor` or a TensorList.
    """

    def __init__(self, x):
        super().__init__()

        if isinstance(x, list) or isinstance(x, TensorList):
            self.x = list(x)
        elif isinstance(x, torch.Tensor):
            self.x = [x]
        else:
            raise TypeError("x must be a list of torch.Tensor or a single torch.Tensor")

        self.shape = [xi.shape for xi in self.x]

    def __len__(self):
        r"""
        Returns the number of tensors in the list.
        """
        return len(self.x)

    def __getitem__(self, item):
        r"""
        Returns the ith tensor in the list.
        """
        return self.x[item]

    def flatten(self):
        r"""
        Returns a :class:`torch.Tensor` with a flattened version of the list of tensors.
        """
        return torch.cat([xi.flatten() for xi in self.x])

    def append(self, other):
        r"""
        Appends a :class:`torch.Tensor` or a list of :class:`torch.Tensor` to the list.

        """
        if isinstance(other, list):
            self.x += other
        elif isinstance(other, TensorList):
            self.x += other.x
        elif isinstance(other, torch.Tensor):
            self.x.append(other)
        else:
            raise TypeError(
                "the appended item must be a list of :class:`torch.Tensor` or a single :class:`torch.Tensor`"
            )
        return self

    def __add__(self, other):
        r"""

        Adds two TensorLists. The sizes of the tensor lists must match.

        """
        if not isinstance(other, list) and not isinstance(other, TensorList):
            return TensorList([xi + other for xi in self.x])
        else:
            return TensorList([xi + otheri for xi, otheri in zip(self.x, other)])

    def __mul__(self, other):
        r"""

        Multiply two TensorLists. The sizes of the tensor lists must match.

        """
        if not isinstance(other, list) and not isinstance(other, TensorList):
            return TensorList([xi * other for xi in self.x])
        else:
            return TensorList([xi * otheri for xi, otheri in zip(self.x, other)])

    def __truediv__(self, other):
        r"""

        Divide two TensorLists. The sizes of the tensor lists must match.

        """
        if not isinstance(other, list) and not isinstance(other, TensorList):
            return TensorList([xi / other for xi in self.x])
        else:
            return TensorList([xi / otheri for xi, otheri in zip(self.x, other)])

    def __neg__(self):
        r"""

        Negate a TensorList.
        """
        return TensorList([-xi for xi in self.x])

    def __sub__(self, other):
        r"""

        Substract two TensorLists. The sizes of the tensor lists must match.

        """
        if not isinstance(other, list) and not isinstance(other, TensorList):
            return TensorList([xi - other for xi in self.x])
        else:
            return TensorList([xi - otheri for xi, otheri in zip(self.x, other)])


def randn_like(x):
    r"""
    Returns a :class:`deepinv.utils.TensorList` or :class:`torch.Tensor`
    with the same type as x, filled with standard gaussian numbers.
    """
    if isinstance(x, torch.Tensor):
        return torch.randn_like(x)
    else:
        return TensorList([torch.randn_like(xi) for xi in x])





def zeros_like(x):
    r"""
    Returns a :class:`deepinv.utils.TensorList` or :class:`torch.Tensor`
    with the same type as x, filled with zeros.
    """
    if isinstance(x, torch.Tensor):
        return torch.zeros_like(x)
    else:
        return TensorList([torch.zeros_like(xi) for xi in x])
    



def conjugate_gradient(A, b, max_iter=1e2, tol=1e-5):
    """
    Standard conjugate gradient algorithm to solve Ax=b
        see: http://en.wikipedia.org/wiki/Conjugate_gradient_method
    :param A: Linear operator as a callable function, has to be square!
    :param b: input tensor
    :param max_iter: maximum number of CG iterations
    :param tol: absolute tolerance for stopping the CG algorithm.
    :return: torch tensor x verifying Ax=b

    """

    def dot(s1, s2):
        dot = (s1 * s2).flatten().sum()
        return dot

    x = zeros_like(b)

    r = b
    p = r
    rsold = dot(r, r)

    for i in range(int(max_iter)):
        Ap = A(p)
        alpha = rsold / dot(p, Ap)
        x = x + p * alpha
        r = r + Ap * (-alpha)
        rsnew = dot(r, r)
        # print(rsnew.sqrt())
        if rsnew.sqrt() < tol:
            break
        p = r + p * (rsnew / rsold)
        rsold = rsnew

    return x



class Physics(torch.nn.Module):  # parent class for forward models
    r"""
    Parent class for forward operators

    It describes the general forward measurement process

    .. math::

        y = N(A(x))

    where :math:`x` is an image of :math:`n` pixels, :math:`y` is the measurements of size :math:`m`,
    :math:`A:\xset\mapsto \yset` is a deterministic mapping capturing the physics of the acquisition
    and :math:`N:\yset\mapsto \yset` is a stochastic mapping which characterizes the noise affecting
    the measurements.

    :param callable A: forward operator function which maps an image to the observed measurements :math:`x\mapsto y`.
    :param callable noise_model: function that adds noise to the measurements :math:`N(z)`.
        See the noise module for some predefined functions.
    :param callable sensor_model: function that incorporates any sensor non-linearities to the sensing process,
        such as quantization or saturation, defined as a function :math:`\eta(z)`, such that
        :math:`y=\eta\left(N(A(x))\right)`. By default, the sensor_model is set to the identity :math:`\eta(z)=z`.
    :param int max_iter: If the operator does not have a closed form pseudoinverse, the gradient descent algorithm
        is used for computing it, and this parameter fixes the maximum number of gradient descent iterations.
    :param float tol: If the operator does not have a closed form pseudoinverse, the gradient descent algorithm
        is used for computing it, and this parameter fixes the absolute tolerance of the gradient descent algorithm.

    """

    def __init__(
        self,
        A=lambda x: x,
        noise_model=lambda x: x,
        sensor_model=lambda x: x,
        max_iter=50,
        tol=1e-3,
    ):
        super().__init__()
        self.noise_model = noise_model
        self.sensor_model = sensor_model
        self.forw = A
        self.SVD = False  # flag indicating SVD available
        self.max_iter = max_iter
        self.tol = tol

    def __mul__(self, other):  #  physics3 = physics1 \circ physics2
        r"""
        Concatenates two forward operators :math:`A = A_1\circ A_2` via the mul operation

        The resulting operator keeps the noise and sensor models of :math:`A_1`.

        :param deepinv.physics.Physics other: Physics operator :math:`A_2`
        :return: (deepinv.physics.Physics) concantenated operator

        """
        A = lambda x: self.A(other.A(x))  # (A' = A_1 A_2)
        noise = self.noise_model
        sensor = self.sensor_model
        return Physics(
            A=A,
            noise_model=noise,
            sensor_model=sensor,
            max_iter=self.max_iter,
            tol=self.tol,
        )

    def __add__(self, other):
        r"""
        Stacks two linear forward operators :math:`A(x) = \begin{bmatrix} A_1(x) \\ A_2(x) \end{bmatrix}`
        via the add operation.

        The measurements produced by the resulting model are :class:`deepinv.utils.TensorList` objects, where
        each entry corresponds to the measurements of the corresponding operator.

        :param deepinv.physics.Physics other: Physics operator :math:`A_2`
        :return: (deepinv.physics.Physics) stacked operator

        """
        A = lambda x: TensorList(self.A(x)).append(TensorList(other.A(x)))

        class noise(torch.nn.Module):
            def __init__(self, noise1, noise2):
                super().__init__()
                self.noise1 = noise1
                self.noise2 = noise2

            def forward(self, x):
                return TensorList(self.noise1(x[:-1])).append(self.noise2(x[-1]))

        class sensor(torch.nn.Module):
            def __init__(self, sensor1, sensor2):
                super().__init__()
                self.sensor1 = sensor1
                self.sensor2 = sensor2

            def forward(self, x):
                return TensorList(self.sensor1(x[:-1])).append(self.sensor2(x[-1]))

        return Physics(
            A=A,
            noise_model=noise(self.noise_model, other.noise_model),
            sensor_model=sensor(self.sensor_model, other.sensor_model),
            max_iter=self.max_iter,
            tol=self.tol,
        )

    def reset(self, **kwargs):
        if isinstance(self.noise_model, torch.nn.Module):
            self.noise_model.__init__(**kwargs)

    def forward(self, x):
        r"""
        Computes forward operator :math:`y = N(A(x))` (with noise and/or sensor non-linearities)

        :param torch.Tensor,list[torch.Tensor] x: signal/image
        :return: (torch.Tensor) noisy measurements

        """
        return self.sensor(self.noise(self.A(x)))

    def A(self, x):
        r"""
        Computes forward operator :math:`y = A(x)` (without noise and/or sensor non-linearities)

        :param torch.Tensor,list[torch.Tensor] x: signal/image
        :return: (torch.Tensor) clean measurements

        """
        return self.forw(x)

    def sensor(self, x):
        r"""
        Computes sensor non-linearities :math:`y = \eta(y)`

        :param torch.Tensor,list[torch.Tensor] x: signal/image
        :return: (torch.Tensor) clean measurements
        """
        return self.sensor_model(x)

    def noise(self, x):
        r"""
        Incorporates noise into the measurements :math:`\tilde{y} = N(y)`

        :param torch.Tensor x:  clean measurements
        :return torch.Tensor: noisy measurements

        """
        return self.noise_model(x)

    def A_dagger(self, y, x_init=None):
        r"""
        Computes an inverse of :math:`y = Ax` via gradient descent.

        This function can be overwritten by a more efficient pseudoinverse in cases where closed form formulas exist.

        :param torch.Tensor y: a measurement :math:`y` to reconstruct via the pseudoinverse.
        :param torch.Tensor x_init: initial guess for the reconstruction.
        :return: (torch.Tensor) The reconstructed image :math:`x`.

        """

        if x_init is None:
            x_init = self.A_adjoint(y)

        x = torch.nn.Parameter(x_init, requires_grad=True)

        optimizer = torch.optim.SGD([x], lr=1e-1)
        loss = torch.nn.MSELoss()
        for i in range(self.max_iter):
            err = loss(self.A(x), y)
            optimizer.zero_grad()
            err.backward(retain_graph=True)
            optimizer.step()
            if err < self.tol:
                break

        return x.clone()


class LinearPhysics(Physics):
    r"""
    Parent class for linear operators.

    It describes the linear forward measurement process of the form

    .. math::

        y = N(A(x))

    where :math:`x` is an image of :math:`n` pixels, :math:`y` is the measurements of size :math:`m`,
    :math:`A:\xset\mapsto \yset` is a deterministic linear mapping capturing the physics of the acquisition
    and :math:`N:\yset\mapsto \yset` is a stochastic mapping which characterizes the noise affecting
    the measurements.

    :param callable A: forward operator function which maps an image to the observed measurements :math:`x\mapsto y`.
        It is recommended to normalize it to have unit norm.
    :param callable A_adjoint: transpose of the forward operator, which should verify the adjointness test.
    :param callable noise_model: function that adds noise to the measurements :math:`N(z)`.
        See the noise module for some predefined functions.
    :param callable sensor_model: function that incorporates any sensor non-linearities to the sensing process,
        such as quantization or saturation, defined as a function :math:`\eta(z)`, such that
        :math:`y=\eta\left(N(A(x))\right)`. By default, the sensor_model is set to the identity :math:`\eta(z)=z`.
    :param int max_iter: If the operator does not have a closed form pseudoinverse, the conjugate gradient algorithm
        is used for computing it, and this parameter fixes the maximum number of conjugate gradient iterations.
    :param float tol: If the operator does not have a closed form pseudoinverse, the conjugate gradient algorithm
        is used for computing it, and this parameter fixes the absolute tolerance of the conjugate gradient algorithm.

    """

    def __init__(
        self,
        A=lambda x: x,
        A_adjoint=lambda x: x,
        noise_model=lambda x: x,
        sensor_model=lambda x: x,
        max_iter=50,
        tol=1e-3,
        **kwargs,
    ):
        super().__init__(
            A=A,
            noise_model=noise_model,
            sensor_model=sensor_model,
            max_iter=max_iter,
            tol=tol,
        )

        self.adjoint = A_adjoint

    def A_adjoint(self, y):
        r"""
        Computes transpose of the forward operator :math:`\tilde{x} = A^{\top}y`.
        If :math:`A` is linear, it should be the exact transpose of the forward matrix.

        .. note:

            If problem is non-linear, there is not a well-defined transpose operation,
            but defining one can be useful for some reconstruction networks, such as ``deepinv.models.ArtifactRemoval``.

        :param torch.Tensor y: measurements.
        :return: (torch.Tensor) linear reconstruction :math:`\tilde{x} = A^{\top}y`.

        """
        return self.adjoint(y)

    def __mul__(self, other):
        r"""
        Concatenates two linear forward operators :math:`A = A_1\circ A_2` via the * operation

        The resulting linear operator keeps the noise and sensor models of :math:`A_1`.

        :param deepinv.physics.LinearPhysics other: Physics operator :math:`A_2`
        :return: (deepinv.physics.LinearPhysics) concantenated operator

        """
        A = lambda x: self.A(other.A(x))  # (A' = A_1 A_2)
        A_adjoint = lambda x: other.A_adjoint(self.A_adjoint(x))
        noise = self.noise_model
        sensor = self.sensor_model
        return LinearPhysics(
            A=A,
            A_adjoint=A_adjoint,
            noise_model=noise,
            sensor_model=sensor,
            max_iter=self.max_iter,
            tol=self.tol,
        )

    def __add__(self, other):
        r"""
        Stacks two linear forward operators :math:`A = \begin{bmatrix} A_1 \\ A_2 \end{bmatrix}` via the add operation.

        The measurements produced by the resulting model are :class:`deepinv.utils.TensorList` objects, where
        each entry corresponds to the measurements of the corresponding operator.

        :param deepinv.physics.LinearPhysics other: Physics operator :math:`A_2`
        :return: (deepinv.physics.LinearPhysics) stacked operator

        """
        A = lambda x: TensorList(self.A(x)).append(TensorList(other.A(x)))

        def A_adjoint(y):
            at1 = self.A_adjoint(y[:-1]) if len(y) > 2 else self.A_adjoint(y[0])
            return at1 + other.A_adjoint(y[-1])

        class noise(torch.nn.Module):
            def __init__(self, noise1, noise2):
                super().__init__()
                self.noise1 = noise1
                self.noise2 = noise2

            def forward(self, x):
                return TensorList(self.noise1(x[:-1])).append(self.noise2(x[-1]))

        class sensor(torch.nn.Module):
            def __init__(self, sensor1, sensor2):
                super().__init__()
                self.sensor1 = sensor1
                self.sensor2 = sensor2

            def forward(self, x):
                return TensorList(self.sensor1(x[:-1])).append(self.sensor2(x[-1]))

        return LinearPhysics(
            A=A,
            A_adjoint=A_adjoint,
            noise_model=noise(self.noise_model, other.noise_model),
            sensor_model=sensor(self.sensor_model, other.sensor_model),
            max_iter=self.max_iter,
            tol=self.tol,
        )

    def compute_norm(self, x0, max_iter=100, tol=1e-3, verbose=True):
        r"""
        Computes the spectral :math:`\ell_2` norm (Lipschitz constant) of the operator

        :math:`A^{\top}A`, i.e., :math:`\|A^{\top}A\|`.

        using the `power method <https://en.wikipedia.org/wiki/Power_iteration>`_.

        :param torch.Tensor x0: initialisation point of the algorithm
        :param int max_iter: maximum number of iterations
        :param float tol: relative variation criterion for convergence
        :param bool verbose: print information

        :returns z: (float) spectral norm of :math:`A^{\top}A`, i.e., :math:`\|A^{\top}A\|`.
        """
        x = torch.randn_like(x0)
        x /= torch.norm(x)
        zold = torch.zeros_like(x)
        for it in range(max_iter):
            y = self.A(x)
            y = self.A_adjoint(y)
            z = torch.matmul(x.reshape(-1), y.reshape(-1)) / torch.norm(x) ** 2

            rel_var = torch.norm(z - zold)
            if rel_var < tol and verbose:
                print(
                    f"Power iteration converged at iteration {it}, value={z.item():.2f}"
                )
                break
            zold = z
            x = y / torch.norm(y)

        return z

    def adjointness_test(self, u):
        r"""
        Numerically check that :math:`A^{\top}` is indeed the adjoint of :math:`A`.

        :param torch.Tensor u: initialisation point of the adjointness test method

        :return: (float) a quantity that should be theoretically 0. In practice, it should be of the order of the chosen dtype precision (i.e. single or double).

        """
        u_in = u  # .type(self.dtype)
        Au = self.A(u_in)

        if isinstance(Au, tuple) or isinstance(Au, list):
            V = [randn_like(au) for au in Au]
            Atv = self.A_adjoint(V)
            s1 = 0
            for au, v in zip(Au, V):
                s1 += (v * au).flatten().sum()

        else:
            v = randn_like(Au)
            Atv = self.A_adjoint(v)

            s1 = (v * Au).flatten().sum()

        s2 = (Atv * u_in).flatten().sum()

        return s1 - s2

    def prox_l2(self, z, y, gamma):
        r"""
        Computes proximal operator of :math:`f(x) = \frac{1}{2}\|Ax-y\|^2`, i.e.,

        .. math::

            \underset{x}{\arg\min} \; \frac{\gamma}{2}\|Ax-y\|^2 + \frac{1}{2}\|x-z\|^2

        :param torch.Tensor y: measurements tensor
        :param torch.Tensor z: signal tensor
        :param float gamma: hyperparameter of the proximal operator
        :return: (torch.Tensor) estimated signal tensor

        """
        b = self.A_adjoint(y) + 1 / gamma * z
        H = lambda x: self.A_adjoint(self.A(x)) + 1 / gamma * x
        x = conjugate_gradient(H, b, self.max_iter, self.tol)
        return x

    def A_dagger(self, y):
        r"""
        Computes the solution in :math:`x` to :math:`y = Ax` using the
        ` conjugate gradient method <https://en.wikipedia.org/wiki/Conjugate_gradient_method>`_.

        If the size of :math:`y` is larger than :math:`x` (overcomplete problem), it computes :math:`(A^{\top} A)^{-1} A^{\top} y`,
        otherwise (incomplete problem) it computes :math:`A^{\top} (A A^{\top})^{-1} y`.

        This function can be overwritten by a more efficient pseudoinverse in cases where closed form formulas exist.

        :param torch.Tensor y: a measurement :math:`y` to reconstruct via the pseudoinverse.
        :return: (torch.Tensor) The reconstructed image :math:`x`.

        """
        Aty = self.A_adjoint(y)

        overcomplete = Aty.flatten().shape[0] < y.flatten().shape[0]

        if not overcomplete:
            A = lambda x: self.A(self.A_adjoint(x))
            b = y
        else:
            A = lambda x: self.A_adjoint(self.A(x))
            b = Aty

        x = conjugate_gradient(A=A, b=b, max_iter=self.max_iter, tol=self.tol)

        if not overcomplete:
            x = self.A_adjoint(x)

        return x



def extend_filter(filter):
    b, c, h, w = filter.shape
    w_new = w
    h_new = h

    offset_w = 0
    offset_h = 0

    if w == 1:
        w_new = 3
        offset_w = 1
    elif w % 2 == 0:
        w_new += 1

    if h == 1:
        h_new = 3
        offset_h = 1
    elif h % 2 == 0:
        h_new += 1

    out = torch.zeros((b, c, h_new, w_new), device=filter.device)
    out[:, :, offset_h : h + offset_h, offset_w : w + offset_w] = filter
    return out




def conv(x, filter, padding):
    r"""
    Convolution of x and filter. The transposed of this operation is conv_transpose(x, filter, padding)

    :param x: (torch.Tensor) Image of size (B,C,W,H).
    :param filter: (torch.Tensor) Filter of size (1,C,W,H) for colour filtering or (1,1,W,H) for filtering each channel with the same filter.
    :param padding: (string) options = 'valid','circular','replicate','reflect'. If padding='valid' the blurred output is smaller than the image (no padding), otherwise the blurred output has the same size as the image.

    """
    b, c, h, w = x.shape

    filter = filter.flip(-1).flip(
        -2
    )  # In order to perform convolution and not correlation like Pytorch native conv

    filter = extend_filter(filter)

    ph = (filter.shape[2] - 1) / 2
    pw = (filter.shape[3] - 1) / 2

    if padding == "valid":
        h_out = int(h - 2 * ph)
        w_out = int(w - 2 * pw)
    else:
        h_out = h
        w_out = w
        pw = int(pw)
        ph = int(ph)
        x = F.pad(x, (pw, pw, ph, ph), mode=padding, value=0)

    if filter.shape[1] == 1:
        y = torch.zeros((b, c, h_out, w_out), device=x.device)
        for i in range(b):
            for j in range(c):
                y[i, j, :, :] = F.conv2d(
                    x[i, j, :, :].unsqueeze(0).unsqueeze(1), filter, padding="valid"
                ).unsqueeze(1)
    else:
        y = F.conv2d(x, filter, padding="valid")

    return y


def conv_transpose(y, filter, padding):
    r"""
    Tranposed convolution of x and filter. The transposed of this operation is conv(x, filter, padding)

    :param torch.tensor x: Image of size (B,C,W,H).
    :param torch.tensor filter: Filter of size (1,C,W,H) for colour filtering or (1,C,W,H) for filtering each channel with the same filter.
    :param str padding: options are ``'valid'``, ``'circular'``, ``'replicate'`` and ``'reflect'``.
        If ``padding='valid'`` the blurred output is smaller than the image (no padding)
        otherwise the blurred output has the same size as the image.
    """

    b, c, h, w = y.shape

    filter = filter.flip(-1).flip(
        -2
    )  # In order to perform convolution and not correlation like Pytorch native conv

    filter = extend_filter(filter)

    ph = (filter.shape[2] - 1) / 2
    pw = (filter.shape[3] - 1) / 2

    h_out = int(h + 2 * ph)
    w_out = int(w + 2 * pw)
    pw = int(pw)
    ph = int(ph)

    x = torch.zeros((b, c, h_out, w_out), device=y.device)
    if filter.shape[1] == 1:
        for i in range(b):
            if filter.shape[0] > 1:
                f = filter[i, :, :, :].unsqueeze(0)
            else:
                f = filter

            for j in range(c):
                x[i, j, :, :] = F.conv_transpose2d(
                    y[i, j, :, :].unsqueeze(0).unsqueeze(1), f
                )
    else:
        x = F.conv_transpose2d(y, filter)

    if padding == "valid":
        out = x
    elif padding == "zero":
        out = x[:, :, ph:-ph, pw:-pw]
    elif padding == "circular":
        out = x[:, :, ph:-ph, pw:-pw]
        # sides
        out[:, :, :ph, :] += x[:, :, -ph:, pw:-pw]
        out[:, :, -ph:, :] += x[:, :, :ph, pw:-pw]
        out[:, :, :, :pw] += x[:, :, ph:-ph, -pw:]
        out[:, :, :, -pw:] += x[:, :, ph:-ph, :pw]
        # corners
        out[:, :, :ph, :pw] += x[:, :, -ph:, -pw:]
        out[:, :, -ph:, -pw:] += x[:, :, :ph, :pw]
        out[:, :, :ph, -pw:] += x[:, :, -ph:, :pw]
        out[:, :, -ph:, :pw] += x[:, :, :ph, -pw:]

    elif padding == "reflect":
        out = x[:, :, ph:-ph, pw:-pw]
        # sides
        out[:, :, 1 : 1 + ph, :] += x[:, :, :ph, pw:-pw].flip(dims=(2,))
        out[:, :, -ph - 1 : -1, :] += x[:, :, -ph:, pw:-pw].flip(dims=(2,))
        out[:, :, :, 1 : 1 + pw] += x[:, :, ph:-ph, :pw].flip(dims=(3,))
        out[:, :, :, -pw - 1 : -1] += x[:, :, ph:-ph, -pw:].flip(dims=(3,))
        # corners
        out[:, :, 1 : 1 + ph, 1 : 1 + pw] += x[:, :, :ph, :pw].flip(dims=(2, 3))
        out[:, :, -ph - 1 : -1, -pw - 1 : -1] += x[:, :, -ph:, -pw:].flip(dims=(2, 3))
        out[:, :, -ph - 1 : -1, 1 : 1 + pw] += x[:, :, -ph:, :pw].flip(dims=(2, 3))
        out[:, :, 1 : 1 + ph, -pw - 1 : -1] += x[:, :, :ph, -pw:].flip(dims=(2, 3))

    elif padding == "replicate":
        out = x[:, :, ph:-ph, pw:-pw]
        # sides
        out[:, :, 0, :] += x[:, :, :ph, pw:-pw].sum(2)
        out[:, :, -1, :] += x[:, :, -ph:, pw:-pw].sum(2)
        out[:, :, :, 0] += x[:, :, ph:-ph, :pw].sum(3)
        out[:, :, :, -1] += x[:, :, ph:-ph, -pw:].sum(3)
        # corners
        out[:, :, 0, 0] += x[:, :, :ph, :pw].sum(3).sum(2)
        out[:, :, -1, -1] += x[:, :, -ph:, -pw:].sum(3).sum(2)
        out[:, :, -1, 0] += x[:, :, -ph:, :pw].sum(3).sum(2)
        out[:, :, 0, -1] += x[:, :, :ph, -pw:].sum(3).sum(2)
    return out










class Blur(LinearPhysics):
    r"""

    Blur operator.

    This forward operator performs

    .. math:: y = w*x

    where :math:`*` denotes convolution and :math:`w` is a filter.

    This class uses :meth:`torch.nn.functional.conv2d` for performing the convolutions.

    :param torch.Tensor filter: Tensor of size (1, 1, H, W) or (1, C, H, W) containing the blur filter, e.g., :meth:`deepinv.physics.blur.gaussian_blur`.
    :param str padding: options are ``'valid'``, ``'circular'``, ``'replicate'`` and ``'reflect'``. If ``padding='valid'`` the blurred output is smaller than the image (no padding)
        otherwise the blurred output has the same size as the image.
    :param str device: cpu or cuda.

    """

    def __init__(self, filter, padding="circular", device="cpu", **kwargs):
        super().__init__(**kwargs)
        self.padding = padding
        self.device = device
        self.filter = torch.nn.Parameter(filter, requires_grad=False).to(device)

    def A(self, x):
        return conv(x, self.filter, self.padding)

    def A_adjoint(self, y):
        return conv_transpose(y, self.filter, self.padding)
    




class GaussianNoise(torch.nn.Module):
    r"""

    Gaussian noise :math:`y=z+\epsilon` where :math:`\epsilon\sim \mathcal{N}(0,I\sigma^2)`.

    It can be added to a physics operator in its construction or by setting the ``noise_model``
    attribute of the physics operator.


    ::

        >>> from deepinv.physics import Denoising, GaussianNoise
        >>> import torch
        >>> physics = Denoising()
        >>> physics.noise_model = GaussianNoise()
        >>> x = torch.rand(1, 1, 2, 2)
        >>> y = physics(x)

    :param float sigma: Standard deviation of the noise.

    """

    def __init__(self, sigma=0.1):
        super().__init__()
        self.sigma = torch.nn.Parameter(torch.tensor(sigma), requires_grad=False)

    def forward(self, x):
        r"""
        Adds the noise to measurements x

        :param torch.Tensor x: measurements
        :returns: noisy measurements
        """
        return x + torch.randn_like(x) * self.sigma